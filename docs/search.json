[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "collegebudgets.html",
    "href": "collegebudgets.html",
    "title": "College Sports Budgets Tidy Tuesday",
    "section": "",
    "text": "This data can be found at here.\nIt was gathered from Equity in Sports Data Analysis."
  },
  {
    "objectID": "tweets.html",
    "href": "tweets.html",
    "title": "Donald Trump Tweet Analysis",
    "section": "",
    "text": "This is an analysis of tweets made on Donald Trumps Twitter account from May 4th, 2009 until the eventual suspension of his account on January 8th, 2021.\n\n\nShow code\nlibrary(readr)\ntweets &lt;- read_csv(\"~/Downloads/tweets.csv\",show_col_types = FALSE)\n\n\nFirst we will use the “str_to_lower” function to make it easier for us to find character strings in our data considering some of them are written in all caps. We will also use “str_length” to find the number of characters in each tweet. These new variables will potentially help us create visualizations and make assertions about our data.\n\n\nShow code\nlibrary(stringr)\nlibrary(dplyr)\nlibrary(tidyr)\ntweets&lt;-tweets|&gt;mutate(lower_text = str_to_lower(text))\ntweets&lt;- tweets|&gt;mutate(length=str_length(text))\n\n\nNow we will do our first analysis. I am curious what hashtag he used the most during this time period. The visualization below shows that.\n\n\nShow code\nhashtags&lt;- str_extract_all(tweets$lower_text,\"#\\\\w+\")\nhashtag_counts&lt;- unlist(hashtags)|&gt;\n  table()|&gt;\n  as.data.frame()\nhash_counts_head&lt;-head(arrange(hashtag_counts,desc(Freq)),15)\nhash_counts_head &lt;- hash_counts_head|&gt;\n  rename(Hashtag=Var1,\n         Frequency=Freq)\nhash_counts_head\n\n\n                  Hashtag Frequency\n1              #trump2016       834\n2  #makeamericagreatagain       570\n3                   #maga       528\n4        #celebapprentice       297\n5    #celebrityapprentice       152\n6                      #1       144\n7                  #trump       126\n8           #americafirst       111\n9         #timetogettough       100\n10             #trumpvlog        83\n11         #draintheswamp        79\n12     #trumpforpresident        77\n13               #kag2020        74\n14             #votetrump        70\n15               #covid19        67\n\n\nNow, we can see that #1 is the sixth most common hashtag, but there is a problem. That isn’t a hashtag, it’s just a reference to the number one. So now we will use a lookaround to make sure that there isn’t a number immediately after the hashtag so that we capture only the hashtags that we want.\n\n\nShow code\nhashtags&lt;- str_extract_all(tweets$lower_text,\"#(?!\\\\d)\\\\w+\")\nhashtag_counts&lt;- unlist(hashtags)|&gt;\n  table()|&gt;\n  as.data.frame()\nhash_counts_head&lt;-head(arrange(hashtag_counts,desc(Freq)),15)\nhash_counts_head &lt;- hash_counts_head|&gt;\n  rename(Hashtag=Var1,\n         Frequency=Freq)\nhash_counts_head\n\n\n                  Hashtag Frequency\n1              #trump2016       834\n2  #makeamericagreatagain       570\n3                   #maga       528\n4        #celebapprentice       297\n5    #celebrityapprentice       152\n6                  #trump       126\n7           #americafirst       111\n8         #timetogettough       100\n9              #trumpvlog        83\n10         #draintheswamp        79\n11     #trumpforpresident        77\n12               #kag2020        74\n13             #votetrump        70\n14               #covid19        67\n15        #trump2016https        66\n\n\nWe succesfully used the lookaround to remove the “#1” row! Looking at this table, we can see that many of his top hashtags have to do with his 2016 campaign and patriotic american messaging.\nFor our next visualization, I will look at the influence of tweets with “maga”. MAGA has long been a rallying cry for Trump and his supporters, but does it have an impact on the amount of interaction with his tweets online? We are also removing retweets and replies as they may not always get the same amount of interaction as his tweets.\n\n\nShow code\nlibrary(ggplot2)\ntweets &lt;- tweets|&gt;\n  mutate(has_maga=ifelse(str_detect(lower_text,\"maga\"),\"Yes\",\"No\"))\ntweets_no_rt&lt;-tweets|&gt;\n  filter(isRetweet==\"FALSE\")|&gt;\n  filter(!str_detect(text,\"^@\"))|&gt;\n  filter(!str_detect(text,\"^RT\"))|&gt;\n  filter(!str_detect(text, '^\"+'))\nggplot(tweets_no_rt, aes(y=has_maga,x=favorites))+\n  geom_boxplot()+\n  labs(title = \"MAGA vs No MAGA: Trump Tweets by Number of Likes\",x=\"Likes\",y=\"Contains MAGA?\")\n\n\n\n\n\n\n\n\n\nLet’s zoom in on the IQR to find out a little more about the plot.\n\n\nShow code\nlibrary(ggplot2)\ntweets_no_rt2 &lt;- tweets_no_rt|&gt;\n  filter(favorites&lt;200000)\nggplot(tweets_no_rt2, aes(y=has_maga,x=favorites))+\n  geom_boxplot()+\n  labs(title = \"MAGA vs No MAGA: Trump Tweets by Number of Likes\",x=\"Likes\",y=\"Contains MAGA?\")+\n  xlim(0,200000)\n\n\n\n\n\n\n\n\n\nAlthough his non-MAGA tweets have higher maximum likes number and the distribution is much wider, we can see that the tweets that contain the phrase “MAGA” have more median likes, and a similar 3Q. It is possible that there is some amount of colinnearlity, where the tweets that contain MAGA are more related to his presidency/campaign and are therefore more popular, but that would require further investigation.\nCitation\nShantanu, Roy. “Donald Trump Tweets Dataset.” Kaggle, 2021, www.kaggle.com/datasets/codebreaker619/donald-trump-tweets-dataset. Accessed 5 March 2025"
  },
  {
    "objectID": "projectpart3.html",
    "href": "projectpart3.html",
    "title": "Project Part 3",
    "section": "",
    "text": "Show code\nlibrary(readr)\ngrad_stats &lt;- read_csv(\"~/Downloads/graduation_rate.csv\")\n\n\nIn this part of the project, I will be doing hypothesis testing on whether parental level of education has a significant effect on the college GPA of students. These are our null and alternate hypotheses:\n\\(H_0:\\mu_{high school}=\\mu_{bachelors degree}\\)\n\\(H_a:\\mu_{high school}&lt;\\mu_{bachelors degree}\\)\nFirst we will filter the data so we are just left with students whose parents level of education is either high school or bachelor’s degree.\n\n\nShow code\nlibrary(dplyr)\ngrad_stats &lt;- grad_stats %&gt;%\n  filter(`parental level of education` %in% c(\"high school\", \"bachelor's degree\"))\n\n\nNow we will find our observed difference between the average college gpa of a student whose parents finished high school and a student whose parents have a bachelor’s degree.\n\n\nShow code\ngrad_stats|&gt;\n  group_by(`parental level of education`)|&gt;\n  summarize(meangpa = mean(`college gpa`))\n\n\n# A tibble: 2 × 2\n  `parental level of education` meangpa\n  &lt;chr&gt;                           &lt;dbl&gt;\n1 bachelor's degree                3.45\n2 high school                      3.34\n\n\nShow code\ngrad_stats|&gt;\n  group_by(`parental level of education`)|&gt;\n  summarize(meangpa = mean(`college gpa`))|&gt;\n  summarize(diff=diff(meangpa))\n\n\n# A tibble: 1 × 1\n    diff\n   &lt;dbl&gt;\n1 -0.107\n\n\nNow we will create our null sampling distribution which will let us decide whether our results that we found are statistically significant. To do this we will create a function.\n\n\nShow code\nlibrary(purrr)\nnull_dist &lt;- function(data){\n  mutate(data, gpa_perm=sample(`college gpa`,replace = FALSE))|&gt;\n    group_by(`parental level of education`)|&gt;\n    summarize(obs_gpa=mean(`college gpa`),\n              perm_mean=mean(gpa_perm))|&gt;\n    summarize(obs_diff=diff(obs_gpa),\n              perm_diff=diff(perm_mean))\n}\n\n\nNow we will use the function to plot the distribution and compare it to our observed value.\n\n\nShow code\nlibrary(ggplot2)\nset.seed(1000)\nnull_distribution &lt;- map_dfr(c(1:10000),~null_dist(grad_stats))\nnull_distribution|&gt;\n  ggplot(aes(x=perm_diff))+\n  geom_histogram()+\n  geom_vline(aes(xintercept=obs_diff))+\n  labs(x=\"GPA Difference\", title=\"Null Sampling Distribution of Difference in GPA\")\n\n\n\n\n\n\n\n\n\nShown in this plot is the null sampling distribution for the differences in GPAs given that the null hypothesis is true. Also pictured as a vertical line is the observed value that we got. We can see that our observed value seems to be fairly extreme compared to the null sampling distribution that we found.\nTo figure out how extreme our value is, we will now find the proportion of the reps in the null distribution that were more extreme than our observed value. This is our p-value.\n\n\nShow code\nnull_distribution|&gt;\n  summarize(p_value=round(1-mean(perm_diff&gt;obs_diff),6))\n\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1  0.0001\n\n\nHere we can see that we got a p-value of 0.0001 (one observation out of 10000), very small, and much less than the commonly used significance level 0.05. This implies that if the null hypothesis were true, we would see our observed result around 0.01% of the time. This means that we have grounds to reject the null hypothesis. So our conclusion is that it seems that the education level of parents of a student does play a significant role in their college GPA.\nRattanaporn, Kiattisak. “Graduation Rate” Kaggle, 2023, https://www.kaggle.com/datasets/rkiattisak/graduation-rate. Accessed 2 April 2025"
  },
  {
    "objectID": "Project4.html",
    "href": "Project4.html",
    "title": "Project Part 4",
    "section": "",
    "text": "Late in 2018, Amazon decided to abandon a tool that they had been working on which used a machine learning algorithm to make hiring decisions by observing patterns from past resumes. According to an article from the BBC, the artificial intelligence system was launched in 2014 and was trained on resume data from the past ten years. It would review the resumes of candidates and give them a rating of one to five stars based on their hireability, similar to the way that consumers are able to review Amazon products.\nThe program was ultimately scrapped due to various issues with the fairness and the effectiveness of the tool. The first of these was the tool learning to favor male candidates throughout the process, making them more likely to gain higher ratings and subsequently be hired. According to Reuters, the algorithm taught itself to punish resumes with the word “women” in them, with a prominent example being one resume who’s owner was “women’s chess club captain”. While Amazon quickly edited the tool to ensure this was taken out of the system, that didn’t sufficiently address other concerns, many of them stemming from the fact that the training data included mostly male resumes, due to the dominance of men in the tech industry over the past decade. The other concern with the tool aside from discrimination, according to the BBC, is that it simply wasn’t good at identifying candidates that were qualified for the position, routinely giving high scores to candidates without the necessary education and experience. Now let us get into some of the underlying ethical concerns behind this system.\nA very obvious way to start is by asking the question: are those individuals (measured) representative of the people to whom we’d like to apply the algorithm? As I touched on briefly in the above paragraph, the answer is no. The training data consisted mostly of resumes from past male candidates, causing a clear disadvantage to the female candidates applying for jobs. Some of this discrimination included knocking the use of the word ‘women’, but according to Reuters the technology also favored those who used more masculine language in their resumes. This would lead to the system favoring those resumes that were more characteristically male, and thus creating unfair advantages in the hiring process.\nAnother question that we must look at is this: should gender be a variable? The Civil Rights Act of 1964 states that companies may not discriminate based on gender or race when hiring, and so obviously Amazon wouldn’t have included those as variables in their hiring algorithm. That doesn’t mean however, that the system wasn’t able to pick up which resumes had characteristics more likely to belong to a man and which had characteristics more likely to belong to a woman and use that in the decision making process. While Amazon denies that this algorithm was ever used for hiring decisions, it is clear based on evidence stated above that using it for those purposes would undoubtedly be illegal.\nFor our last two ethical questions about this application of data science, we will use the Data Science Principles and Manifesto as our reference. I want to specifically examine this entry: Build teams with diverse ideas, backgrounds, and strengths. Does this tool help Amazon accomplish that? Well we know that the algorithm favored men over women, and it is likely that the past workers at Amazon were primarily white, so if the system was trained using their resumes, it is likely that there were other discriminatory inclinations of this machine beyond just women.\nOur final question that we will examine is: Recognize and mitigate bias in ourselves and in the data we use. To Amazon’s credit, they found that the methods that they were using contained bias, took steps to mitigate the bias, and eventually when it became clear that that would be too difficult, eliminated the algorithm altogether. According to Reuters, Amazon claimed that the information from the algorithm was never used in hiring decisions although recruiters had looked at it. This is a lesson that it is important to consider the biases in our data or systems before we use it for decision making purposes.\nThere is a lot we can learn from the situation that arose from Amazon’s attempt at making an algorithm to read resumes and rate candidates based on those resumes. Among those lessons: Recognize bias, build diverse teams, investigate your variables and make sure your training data fits with what you are trying to use your algorithm for.\nCitations BBC News. “Amazon Scrapped ‘Sexist AI’ Tool.” BBC News, 10 Oct. 2018, https://www.bbc.com/news/technology-45809919.\nDastin, Jeffrey. “Amazon Scraps Secret AI Recruiting Tool That Showed Bias against Women.” Reuters, 10 Oct. 2018, https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G/."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Noah Manning’s Website",
    "section": "",
    "text": "Welcome to my website!\nHere’s a little about me: I am a sophomore at Pomona College, and I study Statistics. In my free time I like to play soccer, basketball and ski. I am on the 5C ski team, and I also enjoy cooking and watching movies. I am originally from Kennebunk, Maine, and I have a sister and two dogs."
  },
  {
    "objectID": "marchmadness.html",
    "href": "marchmadness.html",
    "title": "March Madness Tidy Tuesday",
    "section": "",
    "text": "This data can be found here.\nIt was found on ESPN, Kenpom, Yahoo Sports and Heat Check CBB."
  },
  {
    "objectID": "project3.html",
    "href": "project3.html",
    "title": "Project Part 3",
    "section": "",
    "text": "Show code\nlibrary(readr)\ngrad_stats &lt;- read_csv(\"~/Downloads/graduation_rate.csv\")\n\n\nIn this part of the project, I will be doing hypothesis testing on whether parental level of education has a significant effect on the college GPA of students. These are our null and alternate hypotheses:\n\\(H_0:\\mu_{high school}=\\mu_{bachelors degree}\\)\n\\(H_a:\\mu_{high school}&lt;\\mu_{bachelors degree}\\)\nFirst we will filter the data so we are just left with students whose parents level of education is either high school or bachelor’s degree.\n\n\nShow code\nlibrary(dplyr)\ngrad_stats &lt;- grad_stats %&gt;%\n  filter(`parental level of education` %in% c(\"high school\", \"bachelor's degree\"))\n\n\nNow we will find our observed difference between the average college gpa of a student whose parents finished high school and a student whose parents have a bachelor’s degree.\n\n\nShow code\ngrad_stats|&gt;\n  group_by(`parental level of education`)|&gt;\n  summarize(meangpa = mean(`college gpa`))\n\n\n# A tibble: 2 × 2\n  `parental level of education` meangpa\n  &lt;chr&gt;                           &lt;dbl&gt;\n1 bachelor's degree                3.45\n2 high school                      3.34\n\n\nShow code\ngrad_stats|&gt;\n  group_by(`parental level of education`)|&gt;\n  summarize(meangpa = mean(`college gpa`))|&gt;\n  summarize(diff=diff(meangpa))\n\n\n# A tibble: 1 × 1\n    diff\n   &lt;dbl&gt;\n1 -0.107\n\n\nNow we will create our null sampling distribution which will let us decide whether our results that we found are statistically significant. To do this we will create a function.\n\n\nShow code\nlibrary(purrr)\nnull_dist &lt;- function(data){\n  mutate(data, gpa_perm=sample(`college gpa`,replace = FALSE))|&gt;\n    group_by(`parental level of education`)|&gt;\n    summarize(obs_gpa=mean(`college gpa`),\n              perm_mean=mean(gpa_perm))|&gt;\n    summarize(obs_diff=diff(obs_gpa),\n              perm_diff=diff(perm_mean))\n}\n\n\nNow we will use the function to plot the distribution and compare it to our observed value.\n\n\nShow code\nlibrary(ggplot2)\nset.seed(1000)\nnull_distribution &lt;- map_dfr(c(1:10000),~null_dist(grad_stats))\nnull_distribution|&gt;\n  ggplot(aes(x=perm_diff))+\n  geom_histogram()+\n  geom_vline(aes(xintercept=obs_diff))+\n  labs(x=\"GPA Difference\", title=\"Null Sampling Distribution of Difference in GPA\")\n\n\n\n\n\n\n\n\n\nShown in this plot is the null sampling distribution for the differences in GPAs given that the null hypothesis is true. Also pictured as a vertical line is the observed value that we got. We can see that our observed value seems to be fairly extreme compared to the null sampling distribution that we found.\nTo figure out how extreme our value is, we will now find the proportion of the reps in the null distribution that were more extreme than our observed value. This is our p-value.\n\n\nShow code\nnull_distribution|&gt;\n  summarize(p_value=round(1-mean(perm_diff&gt;obs_diff),6))\n\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1  0.0001\n\n\nHere we can see that we got a p-value of 0.0001 (one observation out of 10000), very small, and much less than the commonly used significance level 0.05. This implies that if the null hypothesis were true, we would see our observed result around 0.01% of the time. This means that we have grounds to reject the null hypothesis. So our conclusion is that it seems that the education level of parents of a student does play a significant role in their college GPA.\n#test changes"
  }
]